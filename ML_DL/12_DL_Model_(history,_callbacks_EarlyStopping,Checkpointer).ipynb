{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "12_DL_Model_(history, callbacks_EarlyStopping,Checkpointer).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bob8dod/ML-studying/blob/main/ML_DL/12_DL_Model_(history%2C_callbacks_EarlyStopping%2CCheckpointer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra9uDSAhN7TH"
      },
      "source": [
        "#Using Package\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping #Using Callbacks for saving, earlystopping\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj_AZOgxN7TS"
      },
      "source": [
        "#Seed setting\n",
        "seed = 3\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqRn7TE1N7TT",
        "outputId": "bf9f256a-06f8-4586-f65b-0e41d43a1463"
      },
      "source": [
        "#Data preprocessing\n",
        "pre_df = pd.read_csv('./dataset/wine.csv', header=None)\n",
        "df = pre_df.sample(frac=0.15) #Import only 15% of total data(because of a vast amount of Data)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6245</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.037</td>\n",
              "      <td>24.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.99094</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.55</td>\n",
              "      <td>10.65</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>10.2</td>\n",
              "      <td>0.670</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.054</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.99760</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.00</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>8.4</td>\n",
              "      <td>0.715</td>\n",
              "      <td>0.20</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.076</td>\n",
              "      <td>10.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99735</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.64</td>\n",
              "      <td>9.40</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.51</td>\n",
              "      <td>11.8</td>\n",
              "      <td>0.044</td>\n",
              "      <td>62.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>0.99760</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.44</td>\n",
              "      <td>8.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.14</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.086</td>\n",
              "      <td>9.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.99824</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.64</td>\n",
              "      <td>10.50</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0      1     2     3      4     5      6        7     8     9      10  \\\n",
              "6245   5.9  0.180  0.28   1.0  0.037  24.0   88.0  0.99094  3.29  0.55  10.65   \n",
              "486   10.2  0.670  0.39   1.9  0.054   6.0   17.0  0.99760  3.17  0.47  10.00   \n",
              "273    8.4  0.715  0.20   2.4  0.076  10.0   38.0  0.99735  3.31  0.64   9.40   \n",
              "1993   6.8  0.370  0.51  11.8  0.044  62.0  163.0  0.99760  3.19  0.44   8.80   \n",
              "885    8.9  0.750  0.14   2.5  0.086   9.0   30.0  0.99824  3.34  0.64  10.50   \n",
              "\n",
              "      11  12  \n",
              "6245   7   0  \n",
              "486    5   1  \n",
              "273    5   1  \n",
              "1993   5   0  \n",
              "885    5   1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZCDWG73N7TV"
      },
      "source": [
        "data = df.values\n",
        "X = data[:,0:12]\n",
        "Y = data[:,12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMWi8r8N7TV"
      },
      "source": [
        "#Model Making, Setting\n",
        "model=Sequential()\n",
        "model.add(Dense(30,input_dim=12,activation='relu'))\n",
        "model.add(Dense(12,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z02VVTdYN7TW"
      },
      "source": [
        "#CheckPointer _ Saving record of model\n",
        "MODEL_DIR = './model/'\n",
        "if not os.path.exists(MODEL_DIR): \n",
        "    os.mkdir(MODEL_DIR) #model 파일이 없다면 생성하기\n",
        "\n",
        "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\" #저장 경로 및 제목설정\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8oj-PzqN7TX"
      },
      "source": [
        "#EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=30) #if it's same during 30times, Stop Training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5YiYWaWN7TX",
        "outputId": "1ac4214b-a1e0-46e0-a648-6f45f8957dd0"
      },
      "source": [
        "#Save the training process for Graph\n",
        "history = model.fit(X,Y,validation_split=0.2,epochs=500, batch_size=50, verbose=1, callbacks=[early_stop])# +checkpointer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 1.2373 - accuracy: 0.7124 - val_loss: 0.4576 - val_accuracy: 0.7795\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.7168 - val_loss: 0.4259 - val_accuracy: 0.8205\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8622 - val_loss: 0.2654 - val_accuracy: 0.9026\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.9037 - val_loss: 0.2135 - val_accuracy: 0.9385\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.9186 - val_loss: 0.2329 - val_accuracy: 0.9179\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.9085 - val_loss: 0.1928 - val_accuracy: 0.9385\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8985 - val_loss: 0.1895 - val_accuracy: 0.9231\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.9185 - val_loss: 0.1870 - val_accuracy: 0.9179\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.9140 - val_loss: 0.1857 - val_accuracy: 0.9231\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.9176 - val_loss: 0.2155 - val_accuracy: 0.9179\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9297 - val_loss: 0.2030 - val_accuracy: 0.9231\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9110 - val_loss: 0.1965 - val_accuracy: 0.9231\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2899 - accuracy: 0.9030 - val_loss: 0.1737 - val_accuracy: 0.9385\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.9128 - val_loss: 0.1775 - val_accuracy: 0.9179\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9095 - val_loss: 0.1771 - val_accuracy: 0.9179\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9188 - val_loss: 0.1917 - val_accuracy: 0.9231\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9295 - val_loss: 0.2039 - val_accuracy: 0.9282\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2258 - accuracy: 0.9345 - val_loss: 0.1655 - val_accuracy: 0.9385\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9255 - val_loss: 0.1742 - val_accuracy: 0.9179\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9216 - val_loss: 0.1850 - val_accuracy: 0.9231\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2309 - accuracy: 0.9206 - val_loss: 0.1629 - val_accuracy: 0.9333\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1852 - accuracy: 0.9297 - val_loss: 0.1957 - val_accuracy: 0.9231\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9190 - val_loss: 0.2084 - val_accuracy: 0.9333\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9279 - val_loss: 0.1663 - val_accuracy: 0.9282\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.9254 - val_loss: 0.1564 - val_accuracy: 0.9436\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9333 - val_loss: 0.1578 - val_accuracy: 0.9333\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9230 - val_loss: 0.1553 - val_accuracy: 0.9385\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9305 - val_loss: 0.1643 - val_accuracy: 0.9333\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9243 - val_loss: 0.1575 - val_accuracy: 0.9385\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9313 - val_loss: 0.1771 - val_accuracy: 0.9282\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9374 - val_loss: 0.1978 - val_accuracy: 0.9385\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9395 - val_loss: 0.1807 - val_accuracy: 0.9333\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9240 - val_loss: 0.1527 - val_accuracy: 0.9436\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 0.9329 - val_loss: 0.1692 - val_accuracy: 0.9436\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9379 - val_loss: 0.1888 - val_accuracy: 0.9436\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9264 - val_loss: 0.1460 - val_accuracy: 0.9436\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9338 - val_loss: 0.1438 - val_accuracy: 0.9385\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9341 - val_loss: 0.1416 - val_accuracy: 0.9436\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9335 - val_loss: 0.1346 - val_accuracy: 0.9436\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9299 - val_loss: 0.1445 - val_accuracy: 0.9487\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9289 - val_loss: 0.1339 - val_accuracy: 0.9436\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9284 - val_loss: 0.1323 - val_accuracy: 0.9436\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9298 - val_loss: 0.1300 - val_accuracy: 0.9538\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9407 - val_loss: 0.1282 - val_accuracy: 0.9436\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9398 - val_loss: 0.1399 - val_accuracy: 0.9590\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9378 - val_loss: 0.1256 - val_accuracy: 0.9538\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1774 - accuracy: 0.9456 - val_loss: 0.1288 - val_accuracy: 0.9538\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9305 - val_loss: 0.1263 - val_accuracy: 0.9538\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.9249 - val_loss: 0.1297 - val_accuracy: 0.9590\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9370 - val_loss: 0.1296 - val_accuracy: 0.9538\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9325 - val_loss: 0.1190 - val_accuracy: 0.9538\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9435 - val_loss: 0.1228 - val_accuracy: 0.9538\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.9479 - val_loss: 0.1147 - val_accuracy: 0.9538\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9433 - val_loss: 0.1437 - val_accuracy: 0.9692\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9546 - val_loss: 0.1132 - val_accuracy: 0.9590\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9323 - val_loss: 0.1179 - val_accuracy: 0.9641\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.9495 - val_loss: 0.1150 - val_accuracy: 0.9487\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9502 - val_loss: 0.1104 - val_accuracy: 0.9487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9567 - val_loss: 0.1544 - val_accuracy: 0.9641\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9502 - val_loss: 0.1132 - val_accuracy: 0.9692\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9487 - val_loss: 0.1206 - val_accuracy: 0.9692\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9548 - val_loss: 0.1255 - val_accuracy: 0.9692\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9562 - val_loss: 0.1058 - val_accuracy: 0.9692\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9559 - val_loss: 0.1153 - val_accuracy: 0.9692\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9616 - val_loss: 0.1068 - val_accuracy: 0.9744\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9622 - val_loss: 0.1228 - val_accuracy: 0.9692\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9486 - val_loss: 0.1021 - val_accuracy: 0.9692\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9603 - val_loss: 0.0996 - val_accuracy: 0.9641\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9587 - val_loss: 0.1019 - val_accuracy: 0.9692\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9600 - val_loss: 0.1183 - val_accuracy: 0.9692\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9454 - val_loss: 0.1028 - val_accuracy: 0.9692\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9535 - val_loss: 0.0984 - val_accuracy: 0.9692\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9560 - val_loss: 0.1014 - val_accuracy: 0.9744\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9603 - val_loss: 0.0975 - val_accuracy: 0.9744\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9558 - val_loss: 0.0976 - val_accuracy: 0.9744\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9547 - val_loss: 0.0938 - val_accuracy: 0.9692\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9570 - val_loss: 0.1091 - val_accuracy: 0.9692\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9690 - val_loss: 0.1000 - val_accuracy: 0.9744\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9684 - val_loss: 0.0921 - val_accuracy: 0.9744\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9654 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9711 - val_loss: 0.0935 - val_accuracy: 0.9744\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9644 - val_loss: 0.1051 - val_accuracy: 0.9692\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9759 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9550 - val_loss: 0.0929 - val_accuracy: 0.9744\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9505 - val_loss: 0.1083 - val_accuracy: 0.9692\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9603 - val_loss: 0.0896 - val_accuracy: 0.9744\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9574 - val_loss: 0.0941 - val_accuracy: 0.9641\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9547 - val_loss: 0.0879 - val_accuracy: 0.9692\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9575 - val_loss: 0.0956 - val_accuracy: 0.9744\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9610 - val_loss: 0.0851 - val_accuracy: 0.9744\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9528 - val_loss: 0.0854 - val_accuracy: 0.9744\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9695 - val_loss: 0.0886 - val_accuracy: 0.9795\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9473 - val_loss: 0.0831 - val_accuracy: 0.9795\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9642 - val_loss: 0.1280 - val_accuracy: 0.9590\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9709 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9626 - val_loss: 0.0944 - val_accuracy: 0.9744\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9672 - val_loss: 0.0873 - val_accuracy: 0.9795\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9649 - val_loss: 0.0872 - val_accuracy: 0.9744\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9736 - val_loss: 0.0824 - val_accuracy: 0.9795\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9658 - val_loss: 0.0806 - val_accuracy: 0.9795\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9496 - val_loss: 0.0955 - val_accuracy: 0.9692\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9684 - val_loss: 0.0811 - val_accuracy: 0.9744\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9626 - val_loss: 0.0829 - val_accuracy: 0.9744\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9512 - val_loss: 0.0851 - val_accuracy: 0.9744\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9754 - val_loss: 0.0797 - val_accuracy: 0.9795\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9674 - val_loss: 0.0798 - val_accuracy: 0.9795\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9593 - val_loss: 0.1195 - val_accuracy: 0.9590\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9721 - val_loss: 0.0768 - val_accuracy: 0.9795\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9716 - val_loss: 0.0776 - val_accuracy: 0.9795\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9514 - val_loss: 0.0793 - val_accuracy: 0.9795\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9814 - val_loss: 0.1200 - val_accuracy: 0.9590\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9776 - val_loss: 0.0756 - val_accuracy: 0.9846\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9680 - val_loss: 0.0744 - val_accuracy: 0.9846\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.9674 - val_loss: 0.0746 - val_accuracy: 0.9846\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9685 - val_loss: 0.0745 - val_accuracy: 0.9897\n",
            "Epoch 116/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9598 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9671 - val_loss: 0.0897 - val_accuracy: 0.9641\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9762 - val_loss: 0.0759 - val_accuracy: 0.9795\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9716 - val_loss: 0.0837 - val_accuracy: 0.9795\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9753 - val_loss: 0.0761 - val_accuracy: 0.9846\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9769 - val_loss: 0.0905 - val_accuracy: 0.9692\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9767 - val_loss: 0.0724 - val_accuracy: 0.9846\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9688 - val_loss: 0.0736 - val_accuracy: 0.9846\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9676 - val_loss: 0.0793 - val_accuracy: 0.9744\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9735 - val_loss: 0.0712 - val_accuracy: 0.9897\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9724 - val_loss: 0.0768 - val_accuracy: 0.9846\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9730 - val_loss: 0.0770 - val_accuracy: 0.9795\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9623 - val_loss: 0.0863 - val_accuracy: 0.9692\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9746 - val_loss: 0.0706 - val_accuracy: 0.9897\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9707 - val_loss: 0.0789 - val_accuracy: 0.9744\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9774 - val_loss: 0.0730 - val_accuracy: 0.9846\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9741 - val_loss: 0.0684 - val_accuracy: 0.9897\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9762 - val_loss: 0.0759 - val_accuracy: 0.9744\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9740 - val_loss: 0.0728 - val_accuracy: 0.9846\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9783 - val_loss: 0.0695 - val_accuracy: 0.9897\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9761 - val_loss: 0.0744 - val_accuracy: 0.9795\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9711 - val_loss: 0.0791 - val_accuracy: 0.9795\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9711 - val_loss: 0.0940 - val_accuracy: 0.9692\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9542 - val_loss: 0.0842 - val_accuracy: 0.9744\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9630 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9709 - val_loss: 0.0701 - val_accuracy: 0.9795\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9828 - val_loss: 0.0673 - val_accuracy: 0.9897\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9788 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9762 - val_loss: 0.0838 - val_accuracy: 0.9692\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9703 - val_loss: 0.0968 - val_accuracy: 0.9744\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9809 - val_loss: 0.1385 - val_accuracy: 0.9538\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9523 - val_loss: 0.1022 - val_accuracy: 0.9692\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 0.0666 - val_accuracy: 0.9846\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9686 - val_loss: 0.0641 - val_accuracy: 0.9897\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9797 - val_loss: 0.0803 - val_accuracy: 0.9744\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9699 - val_loss: 0.0640 - val_accuracy: 0.9897\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9813 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9765 - val_loss: 0.0737 - val_accuracy: 0.9846\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9739 - val_loss: 0.0635 - val_accuracy: 0.9897\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9776 - val_loss: 0.0683 - val_accuracy: 0.9846\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9826 - val_loss: 0.0842 - val_accuracy: 0.9795\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9692 - val_loss: 0.0683 - val_accuracy: 0.9846\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9630 - val_loss: 0.1000 - val_accuracy: 0.9744\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9749 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9786 - val_loss: 0.0625 - val_accuracy: 0.9897\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9740 - val_loss: 0.0593 - val_accuracy: 0.9897\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9713 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9762 - val_loss: 0.0773 - val_accuracy: 0.9846\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9588 - val_loss: 0.1148 - val_accuracy: 0.9641\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.0708 - val_accuracy: 0.9897\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9765 - val_loss: 0.0601 - val_accuracy: 0.9846\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9771 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9752 - val_loss: 0.0630 - val_accuracy: 0.9795\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9762 - val_loss: 0.0614 - val_accuracy: 0.9846\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9773 - val_loss: 0.0620 - val_accuracy: 0.9846\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9764 - val_loss: 0.0626 - val_accuracy: 0.9846\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9695 - val_loss: 0.0617 - val_accuracy: 0.9846\n",
            "Epoch 173/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9763 - val_loss: 0.0633 - val_accuracy: 0.9846\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9786 - val_loss: 0.0743 - val_accuracy: 0.9846\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9791 - val_loss: 0.0660 - val_accuracy: 0.9897\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9791 - val_loss: 0.0692 - val_accuracy: 0.9846\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.0678 - val_accuracy: 0.9897\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9794 - val_loss: 0.0712 - val_accuracy: 0.9897\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9733 - val_loss: 0.0635 - val_accuracy: 0.9897\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9698 - val_loss: 0.0590 - val_accuracy: 0.9846\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9750 - val_loss: 0.0593 - val_accuracy: 0.9846\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9655 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9759 - val_loss: 0.0578 - val_accuracy: 0.9846\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9823 - val_loss: 0.0611 - val_accuracy: 0.9897\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9830 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9736 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9784 - val_loss: 0.0611 - val_accuracy: 0.9897\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9812 - val_loss: 0.0617 - val_accuracy: 0.9897\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9802 - val_loss: 0.0743 - val_accuracy: 0.9846\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9853 - val_loss: 0.0641 - val_accuracy: 0.9897\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9792 - val_loss: 0.0651 - val_accuracy: 0.9897\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.0582 - val_accuracy: 0.9897\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9841 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 0.0754 - val_accuracy: 0.9897\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9800 - val_loss: 0.0553 - val_accuracy: 0.9897\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9793 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9778 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9760 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 0.0763 - val_accuracy: 0.9897\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9726 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9803 - val_loss: 0.0576 - val_accuracy: 0.9897\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9837 - val_loss: 0.0588 - val_accuracy: 0.9897\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9850 - val_loss: 0.0536 - val_accuracy: 0.9897\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9828 - val_loss: 0.0561 - val_accuracy: 0.9897\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9727 - val_loss: 0.0531 - val_accuracy: 0.9897\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9776 - val_loss: 0.0545 - val_accuracy: 0.9897\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 0.0808 - val_accuracy: 0.9846\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9868 - val_loss: 0.0537 - val_accuracy: 0.9897\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 0.0543 - val_accuracy: 0.9897\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9886 - val_loss: 0.0556 - val_accuracy: 0.9897\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9809 - val_loss: 0.0558 - val_accuracy: 0.9897\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9828 - val_loss: 0.0519 - val_accuracy: 0.9897\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9933 - val_loss: 0.0600 - val_accuracy: 0.9846\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0619 - val_accuracy: 0.9897\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9811 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9812 - val_loss: 0.0631 - val_accuracy: 0.9897\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9702 - val_loss: 0.0595 - val_accuracy: 0.9897\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9856 - val_loss: 0.0588 - val_accuracy: 0.9897\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9788 - val_loss: 0.0603 - val_accuracy: 0.9897\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9853 - val_loss: 0.0562 - val_accuracy: 0.9897\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 0.0614 - val_accuracy: 0.9897\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.0610 - val_accuracy: 0.9897\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9818 - val_loss: 0.0585 - val_accuracy: 0.9897\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9896 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9758 - val_loss: 0.0534 - val_accuracy: 0.9897\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9829 - val_loss: 0.0623 - val_accuracy: 0.9897\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9813 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9748 - val_loss: 0.0792 - val_accuracy: 0.9846\n",
            "Epoch 230/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9803 - val_loss: 0.0968 - val_accuracy: 0.9692\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0756 - val_accuracy: 0.9897\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9859 - val_loss: 0.0737 - val_accuracy: 0.9846\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9846 - val_loss: 0.0634 - val_accuracy: 0.9897\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.0597 - val_accuracy: 0.9897\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.0531 - val_accuracy: 0.9897\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9765 - val_loss: 0.0546 - val_accuracy: 0.9897\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9842 - val_loss: 0.0562 - val_accuracy: 0.9897\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9781 - val_loss: 0.0554 - val_accuracy: 0.9897\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9833 - val_loss: 0.0533 - val_accuracy: 0.9897\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9813 - val_loss: 0.0568 - val_accuracy: 0.9897\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.0635 - val_accuracy: 0.9897\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 0.0535 - val_accuracy: 0.9897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XXJ-qGJN7TY",
        "outputId": "d1f0054e-e0a2-40b9-cc0d-fc61fa384e23"
      },
      "source": [
        "#Showing on Graph\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSdiyh8GN7TZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}